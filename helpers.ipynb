{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "\n",
    "# fare => lowest : missing fare was 3rd class old Mr. w/out cabin, alone, ticket 4\n",
    "impute_fare = lambda df: df.fare.replace('missing', 9, inplace=True)\n",
    "\n",
    "# age => mode age for group with same pclass honor sisp pach cabin\n",
    "def impute_age(df):\n",
    "    bin_age = bins([13, 21, 26, 32, 40, 50])\n",
    "    features = ['pclass', 'honor', 'sisp', 'pach', 'cabin', 'age']\n",
    "    base = df[df.age != 'missing'][features]\n",
    "    missing = df[df.age == 'missing'][features]\n",
    "    for pid, obs in missing.iterrows():\n",
    "        pclass, honor, sisp, pach, cabin, _ = obs\n",
    "        matches = base.query('pclass == @pclass and honor == @honor and sisp == @sisp and pach == @pach and cabin == @cabin')\n",
    "        if matches.empty:\n",
    "            matches = base[(base.pclass == pclass) & (base.honor == honor)]\n",
    "        mean_age = int(round(matches.age.mean()))\n",
    "        mean_age = bin_age(mean_age)\n",
    "        df.loc[pid, 'age'] = mean_age\n",
    "\n",
    "# Derived features\n",
    "\n",
    "# Traveling with any family?\n",
    "def add_alone(df):\n",
    "    df['alone'] = (df.sisp + df.pach) == 0\n",
    "    return df\n",
    "\n",
    "# Give female children separate honorific\n",
    "# honor == 'miss' and age == '<12'  ==> honor = 'lass'\n",
    "def add_girls_honor(df):\n",
    "    girls = df.query('honor == \"miss\" and age == 13')\n",
    "    for pid in girls.index:\n",
    "        df.loc[pid, 'honor'] = 'lass'\n",
    "\n",
    "# Better class: combine pclass and cabin\n",
    "def add_clare(df):\n",
    "    a = df.query('fare == 9')\n",
    "    b = df.query('pclass == 3 and fare > 9')\n",
    "    c = df.query('pclass < 3 and fare > 9 and fare < 40')\n",
    "    d = df.query('pclass < 3 and fare >= 40')\n",
    "    a.insert(1, 'clare', 1)\n",
    "    b.insert(1, 'clare', 2)\n",
    "    c.insert(1, 'clare', 3)\n",
    "    d.insert(1, 'clare', 4)\n",
    "    res = pd.concat([a, b, c, d], axis=0)\n",
    "    if res.shape[0] != df.shape[0]:\n",
    "        print('Clare error no!!!')\n",
    "    return res\n",
    "\n",
    "def adjust_features(old_df):\n",
    "    df = old_df.copy(deep=True)\n",
    "    impute_fare(df)\n",
    "    impute_age(df)\n",
    "    add_girls_honor(df)\n",
    "    df = add_alone(df)\n",
    "    df = add_clare(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion maps for cleaning data\n",
    "\n",
    "def bins(uppers):\n",
    "    def conversion(v):\n",
    "        last = uppers[-1] + 1\n",
    "        if v == 'missing':\n",
    "            return v\n",
    "        for i, upper in enumerate(uppers):\n",
    "            if v < upper:\n",
    "                return upper\n",
    "        return last\n",
    "    return conversion\n",
    "\n",
    "honorifics = {\n",
    "    'Mr' : 'mr',\n",
    "    'Don': 'mr', 'Sir': 'mr', 'Rev': 'mr', 'Dr': 'mr', 'Major': 'mr', 'Col': 'mr', 'Capt': 'mr', 'Jonkheer': 'mr',\n",
    "    'Master': 'master',\n",
    "    'Mlle': 'miss', 'Ms': 'miss', 'Miss': 'miss',\n",
    "    'Mrs': 'mrs', 'Mme': 'mrs', 'Dona': 'mrs', 'Lady': 'mrs', 'the Countess': 'mrs'\n",
    "}\n",
    "\n",
    "with open('name_origins.pickle', 'rb') as file:\n",
    "    first_name_origins, last_name_origins = pickle.load(file)\n",
    "\n",
    "eng_origin = {'English', 'Irish', 'Cornish', 'Welsh', 'Scottish'}\n",
    "\n",
    "def split_name(name):\n",
    "    match = re.search(r'(\\w+), ([\\w+ ]+)\\. \\(?(\\w+)', name)\n",
    "    if not match:\n",
    "        print('Regex Error: ', name)\n",
    "        return None\n",
    "    honor = honorifics[match.group(2)]\n",
    "    lorigin = last_name_origins[match.group(1)]\n",
    "    forigin = first_name_origins[match.group(3)]\n",
    "    last = 'eng' if lorigin in eng_origin else 'other'\n",
    "    first = 'eng' if forigin in eng_origin else 'other'\n",
    "    if first == last:\n",
    "        origin = first\n",
    "    elif first == 'unknown':\n",
    "        origin = last\n",
    "    elif last == 'unknown':\n",
    "        origin = first\n",
    "    else:\n",
    "        origin = first\n",
    "    return (honor, origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle results and don't repeat unless necessary!\n",
    "# Make conversion maps for name origins\n",
    "def make_name_maps():\n",
    "    names = list(input_values['name'])\n",
    "    fnames = set()\n",
    "    lnames = set()\n",
    "    for name in names:\n",
    "        match = re.search(r'(\\w+),[\\w+ ]+\\. \\(?(\\w+)', name)\n",
    "        if match:\n",
    "            lnames.add(match.group(1))\n",
    "            fnames.add(match.group(2))\n",
    "        else:\n",
    "            print('Regex Error: ', name)\n",
    "    fnames = list(fnames)\n",
    "    lnames = list(lnames)\n",
    "    forigins = defaultdict(dict)\n",
    "    lorigins = defaultdict(dict)\n",
    "    with requests.session() as s:\n",
    "        for name in fnames:\n",
    "            forigins[name] = name_origin(name, s, surname=0)\n",
    "        for name in lnames:\n",
    "            lorigins[name] = name_origin(name, s, surname=1)\n",
    "    return (forigins, lorigins)\n",
    "\n",
    "def name_origin(name, session, surname=0):\n",
    "    url = ('https://www.behindthename.com/name/', 'https://surnames.behindthename.com/name/')[surname]\n",
    "    response = session.get(url + name.strip(), stream=True)\n",
    "    if response.status_code != 200:\n",
    "        return 'unknown'\n",
    "    raw_html = response.content\n",
    "    html = BeautifulSoup(raw_html, 'html.parser')\n",
    "    usage = html.find('a', attrs={'class': 'usg'})\n",
    "    if not usage:\n",
    "        return 'unknown'\n",
    "    usage = re.sub(r' \\(.*\\)', '', usage.string)\n",
    "    split = usage.split()\n",
    "    if len(split) > 1:\n",
    "        usage = split[-1]\n",
    "    return usage\n",
    "\n",
    "#forig, lorig = make_name_maps()\n",
    "#to_save = [forig, lorig]\n",
    "#with open('name_origins.pickle', 'wb') as dump:\n",
    "#    pickle.dump(to_save, dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = lambda df: df.apply(pd.Series.value_counts, axis=0)\n",
    "\n",
    "def get_errors(X, y, model):\n",
    "    errors = []\n",
    "    for i in range(X.shape[0]):\n",
    "        obs = X.iloc[i:i+1]\n",
    "        real = y.iloc[i]\n",
    "        y_pred = model.predict(obs)\n",
    "        if y_pred != [real]:\n",
    "            errors.append(i)\n",
    "    errs = pd.concat([X.iloc[errors], y.iloc[errors]], axis=1, join='outer')\n",
    "    print('Errors:', errs.shape[0])\n",
    "    errs.sort_values('survived', inplace=True)\n",
    "    return errs\n",
    "\n",
    "def test_data(X, y, title, clf, sampler=None, splits=3):\n",
    "    print('\\n', '='*10, title, '='*10)\n",
    "    kfold = KFold(n_splits=splits)\n",
    "    for train_i, test_i in kfold.split(X):\n",
    "        X_train, X_test = X.iloc[train_i], X.iloc[test_i]\n",
    "        y_train, y_test = y.iloc[train_i], y.iloc[test_i]\n",
    "        if sampler:\n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "        model = clf.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        print(' '.join('{0: <7.7}{1}'.format(k, v) for v, k in sorted(zip(model.feature_importances_, X.columns), reverse=True)))\n",
    "        print(metrics.accuracy_score(y_test, preds))\n",
    "        test_survived, test_size = sum(y_test), y_test.shape[0]\n",
    "        print(test_survived, test_size, round(test_survived/test_size), 2)\n",
    "        report = metrics.classification_report(y_test, preds, output_dict=True)\n",
    "        print(' '.join('{0}{1:.2f}'.format(k, v) for k, v in report.items())\n",
    "\n",
    "def sample_features(X, y, clf, population, repeat, fixed=None, size=6):\n",
    "    for _ in range(repeat):\n",
    "        sample = random.sample(population, size)\n",
    "        if fixed is not None:\n",
    "            sample.append(fixed)\n",
    "        X_sample = X.iloc[:, sample]\n",
    "        test_data(X_sample, y, clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
